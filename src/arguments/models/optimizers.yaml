optimizer:
  general:
  adam:
    lr: !!float 1e-3
    beta1: 0.9
    beta2: 0.98
    eps: !!float 1e-9
  adamw:
    lr: !!float 1e-4
    beta1: 0.9
    beta2: 0.999
    eps: !!float 1e-9

lr_scheduler:
  general:
  steplr:
    step_size: 10
    gamma: 0.99
  warmup:
    factor: 1
    step_size: 1
    lr_warmup_step: 40
  cosdecay:
    init_lr: !!float 2e-4      #翻译任务：1e-4，ner任务：5e-5
    mini_lr: !!float 1e-7
    step_size: 100
    warmup_size: 0.02